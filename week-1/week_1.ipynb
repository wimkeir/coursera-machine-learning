{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "**Machine learning** is a subset of **artificial intelligence**. It is about giving computers the ability to learn, without being explicitly programmed.\n",
    "\n",
    "We can write AI programs to do \"simple\" things like find shortest paths, but for more interesting problems, *the machine needs to learn on its own*.\n",
    "\n",
    "Interesting applications:\n",
    "- Natural language (text) processing\n",
    "- Speech processing\n",
    "- Computer vision\n",
    "\n",
    "## Definitions of machine learning\n",
    "\n",
    "Slightly nebulous concept, many conflicting definitions.\n",
    "\n",
    "From Tom Mitchell (Carnegie Mellon):\n",
    "\n",
    "> A computer program learns from experience $E$ with respect to a task $T$ and some performance measure $P$, if its performance of the task improves with experience.\n",
    "\n",
    "Machine learning is mainly split into **supervised learning** and **unsupervised learning** (some definitions also include **reinforcement learning**).\n",
    "\n",
    "## Supervised learning\n",
    "\n",
    "*Supervised* because sample data contains \"correct\" outcomes (it is *labelled*).\n",
    "\n",
    "Can be applied to\n",
    "- **regression** problems (map inputs to *continuous values*)\n",
    "- **classification** problems (map inputs to *discrete values*)\n",
    "\n",
    "## Unsupervised learning\n",
    "\n",
    "*Unsupervised* because data is *unlabelled*. We are given data and told to find relationships or structure.\n",
    "\n",
    "Generally applies to **clustering** problems (sorting data into clusters).\n",
    "\n",
    "> The **cocktail party problem** is an example of unsupervised learning. Given a set of recordings of overlapping voices (where some are louder than others), separate out the voices.\n",
    ">\n",
    "> The \"cocktail party algorithm\" is a single line of (Octave) code:\n",
    "> \n",
    "> `[W, s, v] = svd((repmat(sum(x.*x, 1), size(x, 1), 1).*x)*x')`\n",
    "\n",
    "## Linear regression with one variable\n",
    "\n",
    "This is a *supervised learning* algorithm (also called **univariate linear regression**).\n",
    "\n",
    "Given a *training set* of pairs $(x, y)$ we learn to predict the output $y$ for an unseen $x$.\n",
    "\n",
    "More formally, we input our *training data* into a *learning algorithm* which yields a function $h: X \\rightarrow Y$ (for *hypothesis*) as output, where $h$ maps from inputs to predicted outputs. In other words, we have\n",
    "\n",
    "$$h(x) = y$$\n",
    "\n",
    "In (*univariate*) linear regression problems, we can represent $h$ as follows:\n",
    "\n",
    "$$h_{\\theta} = h = \\theta_{0} + \\theta_{1}x$$\n",
    "\n",
    "In other words, we predict that $y$ is a linear function of $x$. This allows us to fit a straight line ($h_{\\theta}$) to the dataset to predict the outputs. The $(x, y)$ points in the plane are our *training data*, and the straight line $h$ is the *model* we are trying to fit.\n",
    "\n",
    "### Cost functions\n",
    "\n",
    "In a linear regression problem, we have a set of training data $(x_{i}, y_{i})$ for $i \\in [1, m]$, and a model (hypothesis) of the form $h_{\\theta} = \\theta_{0} + \\theta_{1}x$, where the $\\theta_{i}$ values are the *parameters* of our model.\n",
    "\n",
    "The goal is to choose *parameters* that give us an accurate model, in other words, to choose $\\theta_{0}, \\theta_{1}$ such that $h_{\\theta}(x)$ is as close to $y$ as possible for our training data $(x_{i}, y_{i})$. We need to define a **cost function** or **objective function** to minimize.\n",
    "\n",
    "For the univariate linear regression problem, we can use the **(mean) squared error** function, defined as\n",
    "\n",
    "$$J(\\theta_{0}, \\theta_{1}) = \\frac{1}{2m}\\sum_{i=1}^{m}(h_{\\theta}(x_{i}) - y_{i})^{2}$$\n",
    "\n",
    "and can define the problem as the minimization problem\n",
    "\n",
    "$$\\underset{\\theta_{0}\\theta_{1}}{\\text{min}}\\hspace{1mm} J(\\theta_{0}, \\theta_{1})$$\n",
    "\n",
    "or the **least squares problem**. We divide by $m$ to get the mean. The $\\frac{1}{2}$ is there simply to make some of the maths easier (computation of *gradient descent*, as the derivative cancels out the half). If we find parameters such that $J(\\theta_{0}, \\theta_{1}) = 0$, the line will pass through all our data points (though this is not likely).\n",
    "\n",
    "> Summary of **univariate linear regression** problem\n",
    ">\n",
    "> Hypothesis (or model): $h_{\\theta}(x) = \\theta_{0} + \\theta{1}x$\n",
    ">\n",
    "> Parameters: $\\theta_{0}, \\theta_{1}$ (linear y-intercept and gradient of $J$)\n",
    ">\n",
    "> Cost or objective function: $J(\\theta_{0}, \\theta_{1}) = \\frac{1}{2m}\\sum_{i=1}^{m}(h_{\\theta}(x_{i}) - y_{i})^{2}$ (*mean squared error*)\n",
    ">\n",
    "> Goal: $\\underset{\\theta_{0}\\theta_{1}}{\\text{min}}\\hspace{1mm} J(\\theta_{0}, \\theta_{1})$ (*least squares*)\n",
    "\n",
    "Note that $J(\\theta_{0}, \\theta_{1})$ is a function in two variables (ie. a plane, not a line). We seek the point  ($\\theta_{0}, \\theta_{1}$) in the plane that is the \"lowest\" compared to the plane of origin (the value of $J$ is minimised).\n",
    "\n",
    "### Gradient descent\n",
    "\n",
    "**Gradient descent** is a general algorithm (widely used in ML) which we use to *learn the parameters* that minimise our *cost function*.\n",
    "\n",
    "> Summary of the general **gradient descent** problem\n",
    ">\n",
    "> Given some arbitrary function $J(\\theta_{0}, \\theta_{1}, \\ldots, \\theta_{n})$\n",
    ">\n",
    "> We seek $\\underset{\\theta_{0}\\theta_{1} \\ldots \\theta_{n}}{\\text{min}}\\hspace{1mm} J(\\theta_{0}, \\theta_{1}, \\ldots, \\theta_{n})$\n",
    "\n",
    "The process:\n",
    "1. Start with some initial parameters $(\\theta_{0}, \\theta_{1})$\n",
    "2. Keep changing the parameters until we find a minimum $J(\\theta_{0}, \\theta_{1})$\n",
    "\n",
    "The idea is that from each point, we move towards the next point that gets us closer to a minimum - in other words, in the direction of the steepest descent.\n",
    "\n",
    "The *initial parameters* can affect the outcome. We find *local minima*, not necessarily *global minima*.\n",
    "\n",
    "![gradient descent example](files/gradient_descent.png \"Gradient descent\")\n",
    "\n",
    "The algorithm is as follows, we **repeat the following until convergence** for $j \\in [0, n]$:\n",
    "\n",
    "$$\\theta_{j} := \\theta_{j} - \\alpha\\frac{\\partial}{\\partial\\theta_{j}}J(\\theta_{0}, \\theta_{1}, \\ldots, \\theta_{n})$$\n",
    "\n",
    "In other words, take the derivative at each point, and take a \"step\" in the direction of the steepest gradient.\n",
    "\n",
    "The parameter $\\alpha$ is the **learning rate** - essentially how \"aggressive\" the algorithm should be, how big the \"steps\" are that we take.\n",
    "\n",
    "One subtlety is that the parameters $\\theta_{0}, \\theta_{1}, \\ldots, \\theta_{n}$ should be updated *simultaneously*. This means we need to use temporary variables to work out the new values of $\\theta_{0}, \\theta_{1}, \\ldots, \\theta_{n}$ before assigning them to the actual parameter variables.\n",
    "\n",
    "Choosing $\\alpha$:\n",
    "- If $\\alpha$ is too small, gradient descent is slow (too many steps to reach minimum)\n",
    "- If $\\alpha$ is too large, we can overshoot the minimum (gradient descent can fail to converge or even diverge)\n",
    "\n",
    "As we approach a local minimum, the *derivative term* decreases, and eventually has a value of $0$ at the local minimum. This means that we're taking smaller \"steps\" without changing $\\alpha$.\n",
    "\n",
    "### Gradient descent for linear regression\n",
    "\n",
    "> Summary of problem:\n",
    ">\n",
    "> **Linear regression model**: $h_{\\theta}(x) = \\theta_{0} + \\theta{1}x$\n",
    ">\n",
    "> **Cost function**: $J(\\theta_{0}, \\theta_{1}) = \\frac{1}{2m}\\sum_{i=1}^{m}(h_{\\theta}(x_{i}) - y_{i})^{2}$\n",
    ">\n",
    "> **Gradient descent algorithm**: $\\theta_{j} := \\theta_{j} - \\alpha\\frac{\\partial}{\\partial\\theta_{j}}J(\\theta_{0}, \\theta_{1})$ repeated until convergence for $j \\in [0, 1]$\n",
    "\n",
    "We simplify the derivative term as follows\n",
    "\n",
    "$$\\frac{\\partial}{\\partial\\theta_{j}}J(\\theta_{0}, \\theta_{1}) = \\frac{\\partial}{\\partial\\theta_{j}}\\frac{1}{2m}\\sum_{i=1}^{m}(h_{\\theta}(x_{i}) - y_{i})^{2}$$\n",
    "\n",
    "$$\\frac{\\partial}{\\partial\\theta_{j}}J(\\theta_{0}, \\theta_{1}) = \\frac{\\partial}{\\partial\\theta_{j}}\\frac{1}{2m}\\sum_{i=1}^{m}(\\theta_{0} + \\theta_{1}x - y_{i})^{2}$$\n",
    "\n",
    "And so we get the following results for $j=0$ and $j=1$\n",
    "\n",
    "$$j=0: \\frac{\\partial}{\\partial\\theta_{0}}J(\\theta_{0}, \\theta_{1}) = \\frac{1}{m}\\sum_{i=1}^{m}{(h_{\\theta}(x_{i}) - y_{i}})$$\n",
    "$$j=1: \\frac{\\partial}{\\partial\\theta_{1}}J(\\theta_{0}, \\theta_{1}) = \\frac{1}{m}\\sum_{i=1}^{m}{(h_{\\theta}(x_{i}) - y_{i}})x_{i}$$\n",
    "\n",
    "Which gives us the *gradient descent algorithm for linear regression*, which is to repeat the following until convergence:\n",
    "\n",
    "$$\\theta_{0} := \\theta_{0} - \\alpha\\frac{1}{m}\\sum_{i=1}^{m}{(h_{\\theta}(x_{i}) - y_{i}})$$\n",
    "$$\\theta_{1} := \\theta_{1} - \\alpha\\frac{1}{m}\\sum_{i=1}^{m}{(h_{\\theta}(x_{i}) - y_{i}})x_{i}$$\n",
    "\n",
    "Because the cost function for linear regression problems is a *convex function* (bowl-shaped), there is only one local minimum, so we don't need to worry about not finding the global minimum.\n",
    "\n",
    "![gradient descent in linear regression](files/one_local_minimum.png \"Convex cost function\")\n",
    "\n",
    ">This is an example of **batch gradient descent**, since we use the entire set of training data to work out the gradient at each step.\n",
    ">\n",
    "> There exists a *numerical method* to solve for the minimum of the cost function $J(\\theta_{0}, \\theta_{1})$ without needing an *iterative method* (the **normal equations method**).\n",
    ">\n",
    "> However, gradient descent scales better to larget data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
